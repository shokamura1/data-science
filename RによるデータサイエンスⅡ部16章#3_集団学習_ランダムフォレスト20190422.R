# 2019年4月22日 『Rによるデータサイエンス』 Ⅱ部 16章 集団学習

# 『Rによるデータサイエンス』Ⅱ部 16章3篇　集団学習　ランダムフォレスト
# ●16章の構成
#  16-4 ランダムフォレスト
#   16-4-1 ランダムフォレストのアルゴリズム
#   16-4-2 パッケージと関数
#   16-4-3 ケーススタディー
#  16-5 補遺と注釈

# ●16章3篇 集団学習 ランダムフォレストのゴール
# ・ランダムフォレストの基本概念を理解する
# ・パッケージrandomForestを使って、Rで実装出来るようになる


# ●16-4 ランダムフォレスト
# ランダムフォレスト(RF: Random Forest)は、バギングの提案者ブライマンにより提案された比較的新しいデータ解析の方法である。
# 精度及び計算機資源の節約などの面でバギング、ブースティングよりも優れている。


# ●16-4-1 ランダムフォレストのアルゴリズム
# バギングとRFの大きな違いは、バギングでは全ての変数を用いるが、RFでは変数をランダムサンプリングした
# サブセットを使うので、高次元データ解析に向いている点である。
# ランダムサンプリングする変数の数Mは、ユーザーが自由に設定することが出来る。
# ブライマンは、Mとしては変数の数の正の平方根を取ることを進めている。

# RFのアルゴリズムは以下の通りである。
# (1) 与えられたデータセットからB組のブートストラップサンプルを作成する。
# (2) 各々のブートストラップ・サンプルデータを使い、未剪定の最大の決定・回帰木を生成する。
# ただし、分岐のノードはランダムサンプリングされた変数の中の最善のものを用いる。
# (3) すべての結果を統合・組合せ(回帰の問題では平均、分類の問題では多数決)、新しい予測・分類器を構築する。

# RFは多くの工夫が施され、次のような長所を持っていると言われている。
# ・精度が高い
# ・大きいデータに効率的に作動する。何百、何千の変数でも良い
# ・分類に用いる変数の重要度を推定する
# ・欠損値の推測および多くの欠損値を持つデータの正確さの維持に有効である
# ・分類問題における各郡の個体数がアンバランスであるデータにおいてもてエラーのバランスが保たれる
# ・分類と変数の関係に関する情報を計算する
# ・各群の近似の度合が計算できる
# ・外的基準がないデータにも適応できる(個体の類似度の計算など)


# ●16-4-2 パッケージと関数
# ランダムフォレストの専用パッケージrandomForestは、CRANミラーサイトからダウンロード可能。
# ランダムフォレストの分析を行う関数は、randomForest関数である。
# 書式は以下の通り。

# randomForest(formula, data = NULL, ..., subset, na.action = na.fail)

# randomForest関数の引数やそれに関する関数は、bagging関数、adaboost.M1より多い。
# 主な引数、関連関数は以下の通り。

# ・randomForest関数の主な引数
# 引数                説明                  注意点
# formula             モデルの形式          y^x1 + x3のように記する
# x, y                説明変数と目的変数    formula替わりに用いる
# data, subset        使うデータ
# na.action           欠損値の表記型の指定
# ntree               木の数                デフォルト値は500である
# mtry                分岐に用いる変数の数  デフォルトでは、分類の場合は√m、回帰の場合はm/3、mは変数の総数
# importance          変数の重要度          論理値を使って指定、デフォルトはFalse
# proximity           個体の近似度を計算    論理値を使って指定、デフォルトはFalse


# ・randomForest関数と関連する主な関数
# 関数                機能
# print,summary       結果の出力と要約の出力
# plot                木の数と誤り率
# predict             予測と判別
# importance          重要度の計算
# varImpPlot          分類における変数の重要度のグラフ作成
# classCenter         分類におけるクラスの中心を求める
# MDSPlot             MDSの散布図を作成する
# treesize            使った木のサイズ
# varUsed             RFに使った変数の頻度


# ●16-4-3 ケーススタディー
# 前節で利用した乳癌データBreast CancerによるrandomForestの利用例を以下に示す。
# 引数na.action = 'na.omit'はデータセットの中の欠損値を除く。
# その他の引数はデフォルト値を用いる。

install.packages('randomForest'); library(randomForest)
set.seed(20)
BC.rf <- randomForest(Class~., data = BC.train, na.action = 'na.omit')
print(BC.rf)

# 結果のオブジェクトに記録されている項目はsummary関数で確認出来る。

summary(BC.rf)

# それぞれの項目は$***で呼び出すことが出来る。
# 例えば、上記で行ったRFはそのような種類(回帰か分類かなど)であるかに関する情報は以下のコマンドで返す。

BC.rf$type

# 用いた木の数と誤判別率との関係は、plot関数のグラフから読み取ることが出来る。
# 横軸が木の数で、縦軸が誤り率である。以下のコマンドで作成した図から、木の数が200前後を越えると
# 誤判別率は比較的安定することが読み取れる。

plot(BC.rf)

# RFは、判別・回帰における変数の重要度としてジニ係数を計算する。
# 重要度は$importanceで返す。又、VarImpPlot関数でグラフで示すことが出来る。

BC.rf$importance
varImpPlot(BC.rf)

# 構築したRFのモデルを使って、新しいデータについて判別・回帰を行うのには、
# predict関数を以下のように使う。

BC.rfp <- predict(BC.rf, BC.test[, -10])
(BC.rft <- table(BC.test[, 10], BC.rfp))

round(1 - sum(diag(BC.rft))/sum(BC.rft), 3)


# ●16-5 補遺と注釈
# パッケージipred、RWekaにはバギング関数bagging、Baggingが用意去れている。
# ブースティングに関しては、パッケージboostの中に用意されているadaboost関数、
# RWekaの中にAdaBoostM1関数が用意されており、更にパッケージadaもある。

# 本章で紹介した集団学習のバギング、ブースティング、ランダムフォレストが実用化された歴史は長くない。
# ランダムフォレストは、適応性が良く、判別の精度も高いので、幅広い応用が期待出来る。


# 以上