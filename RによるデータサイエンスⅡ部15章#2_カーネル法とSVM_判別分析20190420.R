# 2019年4月20日 『Rによるデータサイエンス』 Ⅱ部 15章 カーネル法とサポートベクターマシン

# 『Rによるデータサイエンス』Ⅱ部 15章2篇　サポートベクターマシン
# ●15章の構成
#  15-3 サポートベクターマシーン
#   15-3-1 サポートベクターマシーンの基礎
#   15-3-2 パッケージと関数
#   15-3-3 判別分析のケーススタディー

# ●15章2篇 サポートベクターマシンのゴール
# ・サポートベクターマシンの基本概念を理解する
# ・パッケージkernlabを使って、Rで実装出来るようになる

# ●15-3 サポートベクターマシーン
# ●15-3-1 サポートベクターマシーンの基礎
# サポートベクターマシン(SVM: Support Vector Machine)は、分類回帰問題を主としたデータ解析方法である。
# 広く知られるようになったのは、1990年代の後半からであり、V. Vapnik氏の貢献が高く評価されている。
# SVMは高次元の分類問題に得意であるとも言われている。SVMは線分離が可能な高次元の仮説空間で、
# 線形的なアプローチで学習を行うモデルである。
# 学習データ集合(x1, y1), (x2, y2),...,(xn. yn)があるとする。
# ここでx = (x1, x2, ..., xp)tは個体の特徴ベクトル、yは目的変数であり、回帰問題では数値、分類門では
# クラスのラベルである。線形回帰と線形判別の問題では、次に示す線形モデルを使う。

# y = pΣi = 1 wixi + b = W X + b

# ●15-3-2 パッケージと関数
# 本節では、パッケージkenlabのSVM関数ksvmを使う。ksvm関数のシンタックスを以下に示す。
# ksvm(formula, data, kernel = 'rbfdot', kpar = list(sigma, 0.1), type =, cross = 0,)

# 引数formulaとdataは判別・回帰関数と同じである。
# 引数kernelとkparは前節の関数kpcaの引数と同じである。引数typeでは分類と回帰のタイプを指定する。
# デフォルトは、目的変数が質的な場合はC-svc分類法、量的な場合はeps-svr回帰を行うように設定されている。
# 分類方法としては'nu-svc', 'C-bsvc'、回帰方法としては'nu-svr', 'eps-svr'がオプションとして用意されている。
# 引数crossでは、n重交差確認法のnを指定する。デフォルトでは、ゼロになっている。
# 訓練結果にテストデータを当てはめる関数は、predict関数になる。


# ●15-3-3 判別分析のケーススタディー
# (1)使うデータ
# パッケージkernlabには、分類問題として面白いデータセットspamが用意されている。
# データセットspamは4601通の電子メールの特徴を58項目に分けて記録したものである。
# 第58列目がクラスのラベルspam、nonspamであり、残りの57項目はメールの特徴項目である。
# spam(スパム)メールとは、受信者の意図を無視して無差別かつ大量に一括して送り込む迷惑メールを指す。

library(kernlab)
data(spam); dim(spam)
table(spam[, 58])

# 返された結果から分かるように、データは1813のspamメールと2788のnon-spamメールから構成されている。
# データセットの第1列～48列までは、データspamの変数の名前に用いた文字列がメールに現れている頻度である。
# ただし、num857のように、num***になっているのは、その数値857が現れた頻度である。
# 49列から54列までは記号;, (, [, $, #, の使用頻度、55列から57列はメールに使われた大文字の平均値、最長の文字数、総数である。

# まずデータセットspamから、サンプリング方法で学習用とスパム用のデータを作成する。
# ここでは学習用のデータの個体数を2500にし、その残りをテスト用にする。

set.seed(50)
tr.num <- sample(4601, 2500)
spam.train <- spam[tr.num, ]
spam.test <- spam[tr.num, ]


# (2)ケーススタディー
# まず、学習用のデータを使った学習結果を次に示す。ただし、交差確認はn = 3にした。

set.seed(50)
(spam.svm <- ksvm(type~., data = spam.train, cross = 3))

# 学習結果にテストデータを当てはめる関数はpredict関数である。
# その利用例を以下に示す。

spam.pre <- predict(spam.svm, spam.test[, -58])
(spam.tab <- table(spam.test[, 58], spam.pre))
1 - sum(diag(spam.tab))/sum(spam.tab)

# 学習結果に、テストデータを当てはめた誤判別率は、約0.0444で、学習データにおける
# 交差確認の誤判別率は、0.082001である。

# 使うデータが2変数で、2クラスに分類する問題の場合は、plot関数を使ってカラフルなサポートベクター散布図を描くことが出来る。
# irisの一部のデータを使った例を以下に示す。黒マークがサポートベクターである。

y <- as.matrix(iris[51:150, 5])
iris1 <- data.frame(iris[51:150, 3:4], y)
set.seed(0)
ir.ksvm <- ksvm(y~., data = iris1)
plot(ir.ksvm, data = iris1[,1:2])
table(iris1$y, predict(ir.ksvm, iris1[,1:2]))


# 以上