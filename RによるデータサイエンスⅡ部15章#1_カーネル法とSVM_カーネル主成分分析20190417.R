# 2019年4月16日 『Rによるデータサイエンス』 Ⅱ部 15章 カーネル法とサポートベクトルマシン

# 『Rによるデータサイエンス』Ⅱ部 15章1篇　カーネル法
# ●15章の構成
#  15-1 カーネルとは
#  15-2 カーネル主成分分析
#   15-2-1 パッケージと関数
#   15-2-2 カーネル主成分分析のケーススタディー

# ●15章 カーネル主成分分析のゴール
# ・カーネル法の基本概念を理解する
# ・パッケージkernlabを使って、Rで実装出来るようになる

# 本章では、カーネル法による主成分分析とサポートベクターマシンを扱う。
# カーネル主成分分析では、非線形の主成分分析の1種である。サポートベクターマシンは、
# パターン分類、回帰分析の新しい方法で、データマイニングの代表的な方法である。

# ●15-1 カーネルとは
# 非線形的なデータ構造を線形構造に変換できれば、線形的なデータ解析手法(線形マシン)で非線形データを扱うことが可能である。
# データを異なる空間に射影することで、非線形構造を線形構造に変換することが可能な場合がある。

# 例えば、2次元平面座標(x, y)上の4つの点A1(1, 1), A2(1, -1), A3(-1, -1), A4(-1, 1)を考える。
# 仮にA1とA3が一つのクラス、A2とA4が一つのクラスだとすると、平面上でクラスの境界線を1本の直線でひけない。
# しかし、新しい変数z = xyを導入し、2次元の平面(x, y)上のデータを3次元空間(x, y, z)に射影すると、
# 両クラスは平面で切り分けることが可能である。例えばz = 0の平面を境界面とすることが出来る。

# カーネル法とは、以下に述べるカーネル関数を借りて、データを表現しなおす方法である。
# カーネル関数では、表現しなおされたデータの連続性と線形性に焦点を当てている。

# カーネル法を取り入れたいくつかのデータや解析方法が提案されている。
# 例えば、カーネル法による密度関数の推定、カーネル主成分分析、カーネル正準相関分析、
# カーネルクラスター分析、カーネル判別分析などがある。
# 近年、カーネル法による分類器サポートベクターマシンが注目を集めている。
# 本章では、カーネル主成分分析とサポートベクターマシンについて解説する。

# ●15-2 カーネル主成分分析
# カーネル主成分分析(KPCA: Kernel Principal Component Analysis)は、非線形主成分分析とも呼ばれている。
# カーネル主成分分析にも、いくつかのアルゴリズムが提案されているが、大まかな流れは以下のステップを取る。

# (1) カーネル関数K(x, z)を決める
# (2) データから写像行列K n * nを求める
# (3) K n * nの固有値と固有ベクトルを求める
# (4) 固有値と固有ベクトルを正規化する


# ●15-2-1 パッケージと関数
# パッケージkernlabには、カーネル主成分分析のkpca関数がある。
# kpca関数のシンタックスは以下の通り。

# kpca(x, kernel = 'rbfdot', features = 0, kpar = list(sigma = 0.1),...)

# 引数xは、マトリックス形式のデータである。
# データがデータフレーム形式の場合は、回帰分析や判別分析の関数用に記号'~'を使った書式が必要になる。

# 引数kernelには、使うカーネル関数を指定する。
# デフォルトには'rbfdot(ガウシアン)'が指定されているが、オプションとして'polydot'(多項式)、
# 'vanilladot'(線形), 'tanhdot'(タンジェント), 'laplacedot'(ラプラシアン), 'besseldot'(ベッセル), 
# 'anovadot'(ANOVA RBF), 'splinedot'(スプライン)のカーネル関数が用意されている。

# 引数featuresでは求める主成分の数を指定する。
# デフォルトは0になっている。引数kparはカーネル関数に使うパラメータを指定する。
# 結果としては、固有値eig()、主成分ベクトルkpc()、主成分得点rotated()などが返される。


# ●15-2-2 カーネル主成分分析のケーススタディー
# データirisを使った4種類の主成分分析の散布図を以下に示す。
# 図で分かるように、カーネル関数及びパラメータによって結果が異なる。

install.packages('kernlab'); library(kernlab)
par(mfrow = c(2, 2), mai = c(rep(0.3, 4)))
x <- as.matrix(iris[, 1:4])
iris.kpc1 <- kpca(x, kernel = 'rbfdot', kpar = list(sigma = 0.1), features = 2)
plot(rotated(iris.kpc1), col = as.integer(iris[, 5]))

# 上記の引数kparをlist(sigma = 0.5))にし、同じ操作を行う
iris.kpc2 <- kpca(x, kernel = 'rbfdot', kpar = list(sigma = 0.5), features = 2)
plot(rotated(iris.kpc2), col = as.integer(iris[, 5]))


iris.kpc3 <- kpca(x, kernel = 'polydot', kpar = list(degree = 1), features = 2)
plot(rotated(iris.kpc3), col = as.integer(iris[, 5]))


# 上記の引数kparをlist(degree = 5)にし、同じ操作を行う
iris.kpc4 <- kpca(x, kernel = 'polydot', kpar = list(degree = 5), features = 2)
plot(rotated(iris.kpc4), col = as.integer(iris[, 5]))


# 上記の引数kparをlist(degree = 6)にし、同じ操作を行う
iris.kpc5 <- kpca(x, kernel = 'polydot', kpar = list(degree = 6), features = 2)
plot(rotated(iris.kpc5), col = as.integer(iris[, 5]))

# kpca関数の結果に基づいて新しいデータnew.dataを当てはめる際には、
# predict(iris.kpc1, new.data)のように書く。


# 以上